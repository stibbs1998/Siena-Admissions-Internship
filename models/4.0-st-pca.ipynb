{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle Component Analysis\n",
    "This notebook uses [sklearn](https://scikit-learn.org/stable/) to perform PCA on the data set altered with [this source code](https://github.com/stibbs1998/admissions_internship/blob/master/src/data/001-st-clean_data.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.style.use('fivethirtyeight') \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src/visualization/')\n",
    "import visualize as vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the .csv file as a DataFrame. We then assign all of the non-object columns to `X`, with the exception of `df['Enrolled']` - the target variable - which is assigned to `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/interim/Third_order_clean_confidential.csv').drop(columns='Unnamed: 0')\n",
    "X = df.select_dtypes(exclude='object').drop(columns='Enrolled').fillna(-999)\n",
    "y = df.Enrolled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before performing PCA on the data set, we have to standardize the `X` DataFrame.  From there we are able to fit the standardized DataFrame and assign it to `x_new`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data before PCA\n",
    "from sklearn.preprocessing import scale\n",
    "scaled = pd.DataFrame(scale(X),columns=X.columns.values)\n",
    "\n",
    "# implementing PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=6).fit(scaled)\n",
    "pca_samples = pca.transform(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a [scree plot](https://en.wikipedia.org/wiki/Scree_plot) of the eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_explained_variance_ratio(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the variance in the DataSet.  Since there are so many columns, it makes sense to look at this in smaller groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions = ['Dimension {}'.format(i) for i in range(1,len(pca.components_)+1)]\n",
    "\n",
    "# # PCA components\n",
    "# components = pd.DataFrame(np.round(pca.components_, 4), columns = scaled.keys()) \n",
    "# components.index = dimensions\n",
    "\n",
    "# # PCA explained variance\n",
    "# ratios = pca.explained_variance_ratio_.reshape(len(pca.components_), 1) \n",
    "# variance_ratios = pd.DataFrame(np.round(ratios, 4), columns = ['Explained Variance']) \n",
    "# variance_ratios.index = dimensions\n",
    "\n",
    "# for i in range(int(len(scaled.columns)/5)):\n",
    "\n",
    "#     # Create a bar plot visualization\n",
    "#     fig, ax = plt.subplots(figsize = (12,6))\n",
    "\n",
    "#     # Plot the feature weights as a function of the components\n",
    "#     components[components.columns[5*i:5*(i+1)]].plot(ax = ax, kind = 'bar')\n",
    "#     ax.set_ylabel(\"Feature Weights\") \n",
    "#     ax.set_xticklabels(dimensions, rotation=0)\n",
    "#     plt.legend(bbox_to_anchor=(1.25,0.5))\n",
    "\n",
    "#     # Display the explained variance ratios# \n",
    "#     for i, ev in enumerate(pca.explained_variance_ratio_): \n",
    "#         ax.text(i-0.40, ax.get_ylim()[1] + 0.05, \"Explained Var\\n %.4f\"%(ev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_results = vis.pca_results(scaled, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(pca_results).sort_values('Dimension 1',axis=1,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a [biplot](https://en.wikipedia.org/wiki/Biplot) to try and identify which variables have relationships with the main principle components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.biplot(X,scaled,pca);\n",
    "# plt.ylim(-5,5);\n",
    "# plt.xlim(-3,3);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
