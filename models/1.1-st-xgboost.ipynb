{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, auc, f1_score, explained_variance_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.insert(0, '../src/visualization/')\n",
    "import visualize as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/interim/Third_order_clean_confidential.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model to see which features most impact enrollment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test data, and fit a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Enrolled','State_grants','Pell_grant', 'HSCEEB', 'ADMT_DEC_CODE',\n",
    "                     'Unique_student_ID','Applied','Accepted']).select_dtypes(exclude='object').fillna(-999)\n",
    "\n",
    "Y = df['Enrolled'].fillna(-999)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "best_params = {'colsample_bytree': 0.8,\n",
    " 'learning_rate': 0.05,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 11,\n",
    " 'missing': -999,\n",
    " 'n_estimators': 500,\n",
    " 'nthread': 4,\n",
    " 'seed': 42,\n",
    " 'silent': 1,\n",
    " 'subsample': 0.8}  # found from GridSearchCV (013-st-model_paramters.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The columns we are using to model our decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(**best_params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print( \"R2 Score: \", r2_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for importance_type in ['weight']:\n",
    "    vis.my_plot_importance(model,figsize=(10,10),importance_type=importance_type);\n",
    "    plt.tight_layout()\n",
    "    plt.title('Feature Importance: importance_type = %s' %importance_type)\n",
    "    plt.savefig(\"../reports/figures/feature_importance/feature_importance_%s.png\" %importance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot shapley values.\n",
    "* *An intuitive way to understand the Shapley value is the following illustration: The feature values enter a room in random order. All feature values in the room participate in the game (= contribute to the prediction). The Shapley value of a feature value is the average change in the prediction that the coalition already in the room receives when the feature value joins them.*\n",
    " \n",
    "* *The interpretation of the Shapley value is: Given the current set of feature values, the contribution of a feature value to the difference between the actual prediction and the mean prediction is the estimated Shapley value.*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[cristophm.gihub.io](https://christophm.github.io/interpretable-ml-book/shapley.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "# explain the model's predictions using SHAP values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above explanation shows features each contributing to push the model output from the base value (the average model output over the training dataset we passed) to the model output. Features pushing the prediction higher are shown in red, those pushing the prediction lower are in blue (these force plots are introduced in our Nature BME paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_plot = shap.summary_plot(shap_values, X, max_display=20, show=True, alpha=0.7,\n",
    "                  plot_type='dot')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"../reports/figures/feature_importance/shapley_summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot this as a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X, max_display=20, show=True,\n",
    "                  plot_type='bar')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"../reports/figures/feature_importance/shapley_summary_bar.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual features.\n",
    "\n",
    "#### X axis is feature value\n",
    "#### Y axis is the associated shapley value (ouput impact)\n",
    "\n",
    "#### Red/Blue is a value of potential interaction effect: Since `TotalWeight` is so highly weighted, I thought it would be important to plot this as the interaction feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature in ['WeightatAcpt','Number_of_campus_visits','Father_Wages',\n",
    "               'Student_income_AGI','HS_Class_size','SAT_combined','ACTComposite',\n",
    "               'SAT_reading','Dist_to_Siena','Need_by_FM','HS_Percentile_rank','HS_GPA']:\n",
    "\n",
    "#     print(feature)\n",
    "    plt.figure()\n",
    "    shap.dependence_plot(feature, shap_values, X,show=False,interaction_index=\"TotalWeight\")\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(  np.nanpercentile(df[feature],5)-0.03*abs(np.nanpercentile(df[feature],5)),1.03*np.nanpercentile(df[feature],95))\n",
    "    plt.savefig(\"../reports/figures/feature_importance/individual_feature-%s.png\" % feature)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosted decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.plot_tree(model, num_trees=0)\n",
    "# fig = plt.gcf()\n",
    "# fig.set_size_inches(75, 50)\n",
    "# # fig.savefig('../reports/figures/tree.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
