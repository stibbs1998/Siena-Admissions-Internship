{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/CriticalPath_Data_EM_Confidential.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make `df['enrolled']` a T/F categorical value to eliminate NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Enrolled'] = df['Enrolled'].map({80:True})\n",
    "df['Enrolled'] = df['Enrolled'].fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminate all HEOP and Albany Med applicants from `df['Application_Type']` in order to lessen noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Application_Type']!='AM') & (df['Application_Type']!='HE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/CriticalPath_Data_EM_Confidential_lessNoise.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that all the NaN values for the interested columns (i.e. `df['IntsStudyAbroad']`) are them saying no.  It was on the application, and if they were truly interested in it, they would've \n",
    "taken the time to hit yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns.values:\n",
    "    if col.startswith(\"Ints\"):\n",
    "        df[col] = df[col].map(dict(zip(df[col].unique(), [False,True])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the columns we MUST get rid of for either: \n",
    "* not enough info to obtain any usefulness out of \n",
    "* are data ONLY obtained after enrollment decision given to the college (i.e. college_chosen_by_non-matrics, work_study, reason_student_withdrew_app, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged = []\n",
    "for col in df.columns.values:\n",
    "    col_len = len(df[~df[col].isnull()])\n",
    "    if col_len < 5000:\n",
    "        \n",
    "        percent_enrolled_col = (len(df[col][df['Enrolled']]) - df[col][df['Enrolled']].isna().sum()) / len(df[~df[col].isnull()])\n",
    "        if  percent_enrolled_col > 0.9 or percent_enrolled_col < 0.1 or col_len < 200:\n",
    "            flagged.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=flagged)\n",
    "df = df.drop(columns=['Indicated_intent_to_apply_for_FA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some columns that repeat information from other columns.\n",
    "* HS_Numeric_Rank, class size, and percentile rank for example\n",
    "* SAT data can probably be concatenated into one column, and the writing section can be dropped (since most colleges didn't seem to look at it anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MAX_SAT_combined'] = df[['MAXSATVerbalMath','SAT_combined']].max(axis=1)\n",
    "df['MAX_SAT_math'] = df[['NEWSATMath','SAT_math']].max(axis=1)\n",
    "df['MAX_SAT_verbal-reading'] = df[['NEWSATVerbal','SAT_reading']].max(axis=1)\n",
    "\n",
    "df = df.drop(columns=['MAXSATVerbalMath','NEWSATVerbal','NEWSATMath','NEWSATVerbalMath','SAT_combined','SAT_reading','SAT_math','SAT_writing'])\n",
    "\n",
    "df = df.drop(columns=['HS_Numeric_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Test_Optional'] = df['Test_Optional'].map({\"TOPT\":True})\n",
    "df['Test_Optional'] = df['Test_Optional'].fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of columns to potentially ignore:\n",
    "* Initial_inquiry_date\n",
    "* Initial_visit_date\n",
    "* Withdrawal_date\n",
    "* WeightatAcpt\n",
    "* TotalWeight\n",
    "* Admission_date $\\to$ could be useful\n",
    "* COA_BUDGET\n",
    "* DOB\n",
    "* COA $\\to$ this DOES look useful\n",
    "* FT_Tuition_Fees ---- this is directly coorelated with year_of_entry\n",
    "* Net_worth_students_bus\n",
    "* Net_worth_students_investments\n",
    "* Students_cash\n",
    "* ANYTHING with \"date\"\n",
    "* REEVAL_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\n",
    "    'Initial_inquiry_date',\n",
    "    'Initial_visit_date',\n",
    "    'Admission_application_date',\n",
    "    'Admission_date',\n",
    "    'Withdrawal_date',\n",
    "    'First_ISIR_Date',\n",
    "    'Last_ISIR_Date',\n",
    "    'Last_award_letter_date',\n",
    "    'REEVAL_status_date',\n",
    "    'FAFSA_Complete_Date'\n",
    "]\n",
    "\n",
    "other_droppables = [\n",
    "    'WeightatAcpt',\n",
    "    'TotalWeight',\n",
    "    'COA_BUDGET',\n",
    "    'DOB',\n",
    "    'FT_Tuition_Fees',\n",
    "    'Net_worth_students_bus',\n",
    "    'Net_worth_students_investments',\n",
    "    'Student_cash',\n",
    "    'REEVAL_status'\n",
    "]\n",
    "        \n",
    "df = df.drop(columns=dates)\n",
    "df = df.drop(columns=other_droppables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode the following columns:\n",
    "\n",
    "* Ethnicity\n",
    "* Application Type\n",
    "* Dorm/Commuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encs = ['Application_Type','Dorm_or_commuter_student']\n",
    "\n",
    "for col in hot_encs:\n",
    "    df=df.merge(pd.get_dummies(df[col],dtype=int),how='outer',left_index=True,right_index=True).drop(columns=[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others that are droppable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ADMT_DEC_CODE','Athletic_based_inst_aid','Recruited_athlete'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write this new data set to a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/interim/CriticalPath_Data_EM_Confidential_second_order.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
