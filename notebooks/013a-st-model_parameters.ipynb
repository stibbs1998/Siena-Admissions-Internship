{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, auc, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.insert(0, '../src/visualization/')\n",
    "import visualize as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/CriticalPath_Data_EM_Confidential_lessNoise.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which columns should be dropped???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntsROTC 757\n",
      "IntsWVCR 565\n",
      "TEC 7\n",
      "Religious_denomination 981\n",
      "Recruited_athlete 502\n",
      "Street2_perm_res 59\n",
      "Admitted_off_waitlist 73\n",
      "Other_federal_grants 347\n",
      "ISTFR 730\n",
      "ROTC_based_inst_aid 4\n",
      "Tuition_waivers_and_exchanges 69\n",
      "Outside_aid 464\n",
      "Work_study 764\n",
      "MERIT_APPEAL_STATUS 57\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns.values:\n",
    "    drop_cols = []\n",
    "    l = len(df[col][~df[col].isnull()]) \n",
    "    if l<1000:\n",
    "        print(col,l)\n",
    "        drop_cols.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test data, and fit a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Enrolled','Admission_status',\n",
    "                     'Unique_student_ID']).select_dtypes([float,bool,int]).fillna(-999)\n",
    "\n",
    "Y = df['Enrolled'].fillna(-999)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print( \"R2 Score: \", r2_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The below three cells are mostly taken from [Alex Furrier](https://github.com/safurrier/hackathon/blob/master/notebooks/03-model.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute force scan for all parameters, here are the tricks\n",
    "* usually max_depth is 6,7,8\n",
    "* learning rate is around 0.05, but small changes may make big diff\n",
    "* tuning min_child_weight subsample colsample_bytree can have \n",
    "* much fun of fighting against overfit \n",
    "* n_estimators is how many round of boosting\n",
    "* finally, ensemble xgboost with multiple seeds may reduce variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'learning_rate': [.001, 0.05, .01], #so called `eta` value\n",
    "              'max_depth': [2, 5, 10, 20],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [.2, .5, 0.8],\n",
    "              'colsample_bytree': [.2, .5, 0.8],\n",
    "              'n_estimators': [5, 50, 500], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [42]}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=-1, \n",
    "                   cv=3, verbose=2, refit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to find best parameters\n",
    "This cell takes ***FOREVER*** to run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the search to produce the best parameters\n",
    "clf.cv_results_['params'][clf.best_index_]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
